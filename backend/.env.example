# Copia este archivo como ".env" dentro de la carpeta backend/
#
# Windows (PowerShell): Copy-Item .env.example .env
# Linux/Mac: cp .env.example .env
#
# IMPORTANTE:
# - Nunca comitees tu archivo .env real (contiene secretos).
# - En Render, DATABASE_URL normalmente lo provee la plataforma.

# --- Core Django ---
DJANGO_SECRET_KEY=change-me
DEBUG=True
ALLOWED_HOSTS=localhost,127.0.0.1

# Entorno:
# - Si no se define, se infiere desde DEBUG:
#   DEBUG=False => production
#   DEBUG=True  => development
# Puedes forzarlo explícitamente:
ENVIRONMENT=development

# --- Frontend base URLs ---
# Usados para construir enlaces (ej. reset password) enviados desde el backend.
FRONTEND_URL_LOCAL=http://localhost:3000
FRONTEND_URL_PROD=https://tu-frontend-en-produccion

# --- Database ---
# Desarrollo:
# - Este proyecto usa migraciones/features compatibles con PostgreSQL.
# - Para correr en local, define DATABASE_URL_LOCAL apuntando a tu Postgres local.
#
# Ejemplo Postgres local:
# DATABASE_URL_LOCAL=postgresql://user:password@localhost:5432/proyecto_libreria

# Producción:
# - En Render normalmente NO necesitas setear esto manualmente.
# - La plataforma define DATABASE_URL automáticamente.
#
# DATABASE_URL=postgresql://user:password@host:5432/dbname

# --- Email (opcional en desarrollo) ---
EMAIL_HOST_USER=
EMAIL_HOST_PASSWORD=

# --- Cloudinary (opcional) ---
CLOUDINARY_CLOUD_NAME=
CLOUDINARY_API_KEY=
CLOUDINARY_API_SECRET=
CLOUDINARY_URL=

# --- LLM / Agente (opcional pero recomendado) ---
# Provider externo (OpenAI/Azure/Anthropic) o compatible (LM Studio/Ollama/vLLM)
LLM_PROVIDER=openai_compatible
LLM_MODEL=llama-3-8b-instruct
# Base URL solo para modo compatible/local (ej. http://localhost:11434/v1)
LLM_BASE_URL=
LLM_API_KEY=
# Tiempo maximo de respuesta (segundos) y limite de tokens (respuesta)
LLM_TIMEOUT_SEC=15
LLM_MAX_TOKENS=512
# Modo de costos: paid (usa key del servidor), byo_key (el usuario aporta), hybrid (prioriza usuario y cae a servidor)
LLM_COST_MODE=paid
# Permitir BYO key en headers (true/false)
LLM_ALLOW_BYO_KEY=false

# --- Vector DB (Chroma) ---
# Regla: todo lo del agente vive en backend/agent/
# Estas variables son OPCIONALES.
# Si existe `backend/agent/vector_db/manifest.json`, el sistema auto-detecta:
# - directorio
# - colección
# - modelo de embeddings y normalización

# Ruta al artefacto Chroma (si no se define, usa ./backend/agent/vector_db)
# VECTOR_DB_DIR=./backend/agent/vector_db

# Override de la colección (si no se define, se toma del manifest)
# VECTOR_COLLECTION=book_catalog

# Override del manifest (si no se define, se busca manifest.json dentro de VECTOR_DB_DIR)
# VECTOR_DB_MANIFEST=./backend/agent/vector_db/manifest.json
